{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb46849a-f119-4949-b073-882098cbc4c1",
   "metadata": {},
   "source": [
    "# 1. Ordinary Least Squares\n",
    ">普通最小二乘法\n",
    "\n",
    "LinearRegression fits a linear model with coefficients w = (w1, w2,......,wn)\n",
    "to minimize the residual sum of squares between the observed targets in the dataset, and the targets predicted by the linear approximation. \n",
    "\n",
    "LinearRegression拟合系数 w = (w1, w2，......，wn) 的线性模型\n",
    "最小化数据集中观测目标与线性逼近预测目标之间的残差平方和。\n",
    "\n",
    "LinearRegression will take in its fit method arrays X, y and will store the coefficients w\n",
    " of the linear model in its coef_ member\n",
    "\n",
    " LinearRegression的fit方法接收数组X, y，并存储系数 w 线性模型的coef_成员:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79d8d616-b171-496f-9b65-a8e92911fd98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5, 0.5])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit([[0, 0], [1, 1], [2, 2]], [0, 1, 2])\n",
    "reg.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938de8d5-bd39-400f-823b-acfdffaf45e3",
   "metadata": {},
   "source": [
    "普通最小二乘法的系数估计依赖于特征的独立性。当特征相关时，设计矩阵的列X\n",
    "具有近似线性依赖性，设计矩阵变得接近奇异，因此，最小二乘估计对观测目标中的随机误差变得非常敏感，产生很大的方差。\n",
    "例如，在没有实验设计的情况下收集数据时，就会出现这种多重共线性的情况"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5bed41-3469-4f70-b910-152a269c017d",
   "metadata": {},
   "source": [
    "**Example**\n",
    "* [Linear Regression Example](http://localhost:8890/notebooks/SKLearn%2Fexamples%2FLinear%20Regression.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee23d484-f5e8-4fcd-9513-00a8272135ec",
   "metadata": {},
   "source": [
    "## 1.2 Non-Negative Least Squares\n",
    "\n",
    "> 非负最小二乘法\n",
    "\n",
    "It is possible to constrain all the coefficients to be non-negative, which may be useful when they represent some physical or naturally non-negative quantities (e.g., frequency counts or prices of goods). LinearRegression accepts a boolean positive parameter: when set to True Non-Negative Least Squares are then applied.\n",
    "\n",
    "可以将所有系数限制为非负，这在它们表示一些物理上或自然上非负的数量(例如频率计数或商品价格)时可能有用。\n",
    "LinearRegression接受一个布尔值正参数:当设置为True时，应用非负最小二乘\n",
    "\n",
    "**Example**\n",
    "* [Non-Negative Least Squares-Examples](http://localhost:8890/notebooks/SKLearn/examples/Non-Negative%20Least%20Squares.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203980b5-8f0a-40dd-a80e-8f7c45e203c4",
   "metadata": {},
   "source": [
    "# 2. Ridge regression and classification\n",
    "\n",
    "> Ridge回归与分类"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b88dce-f938-4199-a78e-ebe7a1d14044",
   "metadata": {},
   "source": [
    "## 2.1 Regression\n",
    "\n",
    "Ridge regression addresses some of the problems of Ordinary Least Squares by imposing a penalty on the size of the coefficients. The ridge coefficients minimize a penalized residual sum of squares\n",
    "\n",
    "Ridge回归通过对系数的大小施加惩罚，解决了普通最小二乘法的一些问题。Ridge系数最小化了惩罚后的残差平方和"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5eb2a9c0-06b1-44cd-bcbb-353069db9c2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge(alpha=0.5)\n",
      "[0.34545455 0.34545455]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.1363636363636364"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.Ridge(alpha=.5)\n",
    "a = reg.fit([[0, 0], [0, 0], [1, 1]], [0, .1, 1])\n",
    "print(a)\n",
    "b = reg.coef_\n",
    "print(b)\n",
    "reg.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57495db4-e660-484c-a3d1-098d494504d4",
   "metadata": {},
   "source": [
    "Note that the class Ridge allows for the user to specify that the solver be automatically chosen by setting solver=\"auto\".  When this option is specified, Ridge will choose between the \"lbfgs\", \"cholesky\", and \"sparse_cg\" solvers.  Ridge will begin checking the conditions shown in the following table from top to bottom.  If the condition is true, the corresponding solver is chosen\n",
    "\n",
    "注意，Ridge类允许用户通过设置solver=\"auto\"来指定自动选择求解器。指定此选项后，Ridge将在\"lbfgs\"、\"cholesky\"和\"sparse_cg\"求解器之间进行选择。Ridge 将开始检查下表所示的条件。如果条件为真，则选择相应的求解器\n",
    "\n",
    "solver参数枚举含义：\n",
    "* 'lbfgs'：The positive=True option is specified.(指定了positive=True选项)\n",
    "* 'cholesky'：The input array X is not sparse.(输入数组X不是稀疏的)\n",
    "* 'sparse_cg'：None of the above conditions are fulfilled.(以上条件都不满足)are fulfilled.itions are fulfilled."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898ead27-8754-4ea7-bf1c-22bc9ec03222",
   "metadata": {},
   "source": [
    "## 2.2 Classification\n",
    "\n",
    "Ridge回归器有一个分类器变体:RidgeClassifier。该分类器首先将二进制目标转换为{-1,1}，然后将问题视为回归任务，优化与上述相同的目标。预测的类别对应回归器预测的正负号。对于多分类问题，将问题视为多输出回归，预测的类别对应于最高值的输出\n",
    "\n",
    "使用(惩罚的)最小二乘损失来拟合分类模型，而不是更传统的logistic或hinge损失，似乎有问题。然而，在实践中，所有这些模型都可以在准确率或精度/召回率方面得到相似的交叉验证分数，而RidgeClassifier使用的惩罚最小二乘损失允许使用非常不同的数值求解器，具有不同的计算性能配置\n",
    "\n",
    "这种分类器有时也称为具有线性核的最小二乘支持向量机"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cde4cfd-7441-4319-8f26-e64e5f997691",
   "metadata": {},
   "source": [
    "**Example**\n",
    "* [Plot Ridge coefficients as a function of the regularization(绘制Ridge系数作为正则化的函数)](http://localhost:8890/notebooks/SKLearn%2Fexamples%2FPlot%20Ridge%20coefficients%20as%20a%20function%20of%20the%20regularization.ipynb)\n",
    "* [Classification of text documents using sparse features(基于稀疏特征的文本分类)](http://localhost:8890/notebooks/SKLearn%2Fexamples%2FClassification%20of%20text%20documents%20using%20sparse%20features.ipynb)\n",
    "* []()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7635458-fb6e-4a33-930a-56956020da2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
